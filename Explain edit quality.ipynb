{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score and explain a `damaging` prediction.\n",
    "\n",
    "Requires the \"editquality\" repository is checked out under your home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awight/venv/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Differences between the current environment and the environment in which the model was constructed environment were detected:\n",
      " - platform 'Linux-4.9.0-6-amd64-x86_64-with-debian-9.4' mismatch with original environment 'Linux-4.16.0-x86_64-with-debian-9.4'\n",
      " - release '4.9.0-6-amd64' mismatch with original environment '4.16.0'\n",
      " - version '#1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02)' mismatch with original environment '#1 SMP Wed Apr 18 14:02:11 PDT 2018'\n",
      " - revscoring_version '2.2.2' mismatch with original environment '2.2.5'\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "from revscoring import Model\n",
    "\n",
    "\n",
    "model_path = os.path.expanduser(\"~/editquality/models/enwiki.damaging.gradient_boosting.model\")\n",
    "sm = Model.load(open(model_path), error_on_env_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mwapi\n",
    "from revscoring.extractors import api\n",
    "\n",
    "extractor = api.Extractor(mwapi.Session(\"https://en.wikipedia.org\", user_agent=\"ORES-LIME demo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set\n",
    "from revscoring.utilities.util import read_observations\n",
    "\n",
    "observations = list(read_observations(open(os.path.expanduser(\"~/editquality/datasets/enwiki.labeled_revisions.w_cache.20k_2015.json\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a revision, extract the features and score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/?diff=846560713\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8c7b410060e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://en.wikipedia.org/?diff={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrev_to_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rev_to_score = 846560713\n",
    "features = [str(f) for f in sm.features]\n",
    "feature_values = np.array(list(extractor.extract(rev_to_score, sm.features)))\n",
    "\n",
    "prediction = sm.score(feature_values)\n",
    "\n",
    "print(\"https://en.wikipedia.org/?diff={}\".format(rev_to_score))\n",
    "print(np.array(list(zip(features, feature_values))))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a LIME explainer for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data into a numpy matrix.\n",
    "\n",
    "train = np.array([np.array([o[\"cache\"][k] for k in features]) for o in observations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Also explain as text, using our own explainer to run variations.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "def score(samples):\n",
    "    raw_results = [np.array([sm.score(v)[\"probability\"][t] for t in [False, True]]) for v in samples]\n",
    "    return np.array(raw_results)\n",
    "\n",
    "categorical_features = [0, 1, 2, 45, 46, 47, 48, 49, 50, 51, 54]\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    train,\n",
    "    mode=\"classification\",\n",
    "    feature_names=features,\n",
    "    categorical_features=categorical_features,\n",
    "    class_names=[\"not damaging\", \"damaging\"],\n",
    "    discretize_continuous=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an explainer for this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(\n",
    "    np.array(feature_values),\n",
    "    score,\n",
    "    num_features=10,\n",
    "    top_labels=2,\n",
    "    model_regressor=LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = exp.as_pyplot_figure(label=int(prediction[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list(label=int(prediction[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
